{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU-bound tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU-bound sub-job 0 started.\n",
      "CPU-bound sub-job 0 finished in 10.27 seconds.\n",
      "CPU-bound job finished in 10.27 seconds with a single thread.\n",
      "CPU-bound sub-job 0 started.\n",
      "CPU-bound sub-job 0 finished in 3.41 seconds.\n",
      "CPU-bound sub-job 1 started.\n",
      "CPU-bound sub-job 1 finished in 3.45 seconds.\n",
      "CPU-bound sub-job 2 started.\n",
      "CPU-bound sub-job 2 finished in 3.47 seconds.\n",
      "CPU-bound job finished in 10.34 seconds with three threads.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def cpu_bound_job(job_id, num):\n",
    "    start_job = time.time()    \n",
    "    print(f\"CPU-bound sub-job {job_id} started.\")\n",
    "    sum = 0\n",
    "    # Simulated CPU-heavy arithmetic calculation.\n",
    "    for i in range(num):\n",
    "        sum += i\n",
    "    duration = time.time() - start_job\n",
    "    print(f\"CPU-bound sub-job {job_id} finished in {duration:.2f} seconds.\", end='\\n')\n",
    "\n",
    "def run_with_threads(n_jobs, num):\n",
    "    threads = []\n",
    "    for _id in range(n_jobs):\n",
    "        # `args` is a tuple specifying the positional arguments for the\n",
    "        # target function, which will be run in an independent thread.\n",
    "        thread = threading.Thread(target=cpu_bound_job, args=(_id, num))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        # With `join`, we wait until the thread terminates, either normally\n",
    "        # or through an unhandled exception.\n",
    "        thread.join()\n",
    "\n",
    "start_one_thread = time.time()\n",
    "# Run with a single thread, with a big number.\n",
    "run_with_threads(n_jobs=1, num=3*10**8)\n",
    "duration = time.time() - start_one_thread\n",
    "print(f\"CPU-bound job finished in {duration:.2f} seconds with a single thread.\")\n",
    "\n",
    "start_three_threads = time.time()\n",
    "# Run with three threads with a smaller number. The total number of three threads\n",
    "# adds up to the one of a single thread so the result is comparable.\n",
    "run_with_threads(n_jobs=3, num=10**8)\n",
    "duration = time.time() - start_three_threads\n",
    "print(f\"CPU-bound job finished in {duration:.2f} seconds with three threads.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to write concurrent Python code with multithreading | by Lynn Kwong | Level Up Coding](https://levelup.gitconnected.com/how-to-write-concurrent-python-code-with-multithreading-b24dec228c43)\n",
    "> When we split the big number into a smaller one and try to do the calculation with three threads, the calculation is not faster than that with a single thread. It means that multi-threading is not applicable for CPU-bound tasks and you should not waste your time trying to speed up CPU-bound applications with multi-threading. Instead, you should try to use the `multiprocessing` package."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IO-bound tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO-bound sub-job 0 started.\n",
      "IO-bound sub-job 0 finished in 9.03 seconds.\n",
      "IO-bound job finished in 9.03 seconds with a single thread.\n",
      "IO-bound sub-job 0 started.\n",
      "IO-bound sub-job 1 started.\n",
      "IO-bound sub-job 2 started.\n",
      "IO-bound sub-job 0 finished in 3.01 seconds.\n",
      "IO-bound sub-job 1 finished in 3.03 seconds.IO-bound sub-job 2 finished in 3.03 seconds.\n",
      "\n",
      "IO-bound job finished in 3.03 seconds with three threads.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def io_bound_job(job_id, num_requests):\n",
    "    start_job = time.time()\n",
    "    print(f\"IO-bound sub-job {job_id} started.\")\n",
    "    for _ in range(num_requests):\n",
    "        # IO-bound jobs spend most of the time waiting for responses.\n",
    "        time.sleep(3)\n",
    "    duration = time.time() - start_job\n",
    "    print(f\"IO-bound sub-job {job_id} finished in {duration:.2f} seconds.\")\n",
    "\n",
    "def run_with_threads(n_jobs, num_requests_per_job):\n",
    "    threads = []\n",
    "    for _id in range(n_jobs):\n",
    "        thread = threading.Thread(target=io_bound_job, args=(_id, num_requests_per_job))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "start_one_thread = time.time()\n",
    "# Run with a single thread:\n",
    "run_with_threads(n_jobs=1, num_requests_per_job=3)\n",
    "duration = time.time() - start_one_thread\n",
    "print(f\"IO-bound job finished in {duration:.2f} seconds with a single thread.\")\n",
    "\n",
    "start_three_threads = time.time()\n",
    "# Run with three threads:\n",
    "run_with_threads(n_jobs=3, num_requests_per_job=1)\n",
    "duration = time.time() - start_three_threads\n",
    "print(f\"IO-bound job finished in {duration:.2f} seconds with three threads.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel simulation prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\marc\\lib\\site-packages\\paramiko\\transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\n",
      "  from cryptography.hazmat.backends import default_backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "\n",
      "knpob@158.132.134.38: dat file received D:\\knpob\\20230613-FE cluster\\output\\e2x1\\e2x1.dat -> D:\\knpob\\e2x1_0\n",
      "1687165442.487509\n",
      "\n",
      "knpob@158.132.134.38: simulation completed\n",
      "1687165442.5030267\n",
      "D:\\knpob\\20230613-FE cluster\\output\\e2x1\\1687165443\\e2x1.t19\n",
      "\n",
      "knpob@158.132.134.38: simulation results feed-backward failed\n",
      "\n",
      "knpob@158.132.134.38: simulation task completed in 2.26s.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "simulation tasks completed in 2.26s with 1 thread.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "import subprocess\n",
    "import paramiko\n",
    "\n",
    "def remote_simulate(host=\"158.132.134.38\", user=\"knpob\", local_dat_folder=\"D:\\\\knpob\\\\20230613-FE cluster\\\\output\\\\e2x1\", remote_dat_folder=\"D:\\\\knpob\\\\e2x1\", dat_file=\"e2x1.dat\", wait_time=1):\n",
    "    start_job = time.time()\n",
    "\n",
    "    # setup ssh tunnel\n",
    "    ssh = paramiko.SSHClient()\n",
    "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    ssh.load_system_host_keys()\n",
    "    ssh.connect(hostname=host, username=user)\n",
    "\n",
    "    # transfer dat file\n",
    "    try:\n",
    "        ssh.exec_command('mkdir {}'.format(remote_dat_folder))\n",
    "        subprocess.check_output(['scp', dat_file, '{}@{}:{}'.format(user, host, remote_dat_folder)], shell=False, cwd=local_dat_folder)\n",
    "        print(\"\\n{}@{}: dat file received {} -> {}\".format(user, host, os.path.join(local_dat_folder, dat_file), remote_dat_folder))\n",
    "    except:\n",
    "        print(\"\\n{}@{}: dat file transfer failed\".format(user, host))\n",
    "        \n",
    "    # launch simulation task\n",
    "    # [ISSUE] wait for simulation completes\n",
    "    try:\n",
    "        print(time.time())\n",
    "        ssh.exec_command('cd {}; & \"C:\\\\Program Files\\\\MSC.Software\\\\Marc\\\\2019.0.0\\\\marc2019\\\\tools\\\\run_marc.bat\" -jid {} -back no -nps 4 -nts 3 -nte 3 -nsolver 6'.format(remote_dat_folder, dat_file))\n",
    "        print(\"\\n{}@{}: simulation completed\".format(user, host))\n",
    "        print(time.time())\n",
    "    except:\n",
    "        print(\"\\n{}@{}: simulation failed\".format(user, host))\n",
    "\n",
    "    # simulation results feedback\n",
    "    # p.s. in production, .t19 should be replaced with .t16\n",
    "    # [ISSUE] dir permission\n",
    "    try:\n",
    "        subprocess.check_output(['scp', \n",
    "            '{}@{}:{}'.format(user, host, os.path.join(remote_dat_folder, dat_file.replace('.dat', '.t19'))),\n",
    "            os.path.join(local_dat_folder, str(int(time.time())), dat_file.replace('.dat', '.t19'))],\n",
    "            shell=False)\n",
    "        subprocess.check_output(['scp', '{}@{}:{}'.format(user, host, \n",
    "            os.path.join(remote_dat_folder, dat_file.replace('.dat', '.sts'))), \n",
    "            os.path.join(local_dat_folder, str(int(time.time())), dat_file.replace('.dat', '.sts'))],\n",
    "            shell=False)\n",
    "        print(\"\\n{}@{}: simulation results feed-backwarded\".format(user, host))\n",
    "    except:\n",
    "        print(\"\\n{}@{}: simulation results feed-backward failed\".format(user, host))\n",
    "\n",
    "    duration = time.time() - start_job\n",
    "    print(\"\\n{}@{}: simulation task completed in {:.2f}s.\".format(user, host, duration))\n",
    "\n",
    "def run_with_threads(n_jobs):\n",
    "    print(\"=\"*100)\n",
    "    start_time = time.time()\n",
    "    threads = []\n",
    "\n",
    "    for id in range(n_jobs):\n",
    "        thread = threading.Thread(target=remote_simulate, kwargs=\n",
    "            {\n",
    "                'remote_dat_folder': \"{}_{}\".format(\"D:\\\\knpob\\\\e2x1\", id),\n",
    "            })\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    print(\"-\"*100)\n",
    "    print(\"simulation tasks completed in {:.2f}s with {} thread.\".format(duration, n_jobs))\n",
    "\n",
    "run_with_threads(n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
